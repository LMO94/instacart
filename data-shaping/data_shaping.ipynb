{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit ('sdgintelligence': conda)",
   "metadata": {
    "interpreter": {
     "hash": "4d198db3004a5d782a9b125a9ca7c280e15699d0f763bb373d27ceb8bdaa546a"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "from os import listdir\n",
    "from os import cpu_count\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_cores = cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [file.split('.')[0] for file in listdir(\"../data\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_expr = ', '.join(f'pd.read_csv(\\'../data/{file}.csv\\')' for file in files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all files\n",
    "products, orders, departments, order_products_train, aisles, order_products_prior, sample_submission = eval(eval_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the orders DataFrame with order_products_prior to get combined dataframe with previous orders\n",
    "prior_orders = pd.merge(orders, order_products_prior, on='order_id', how='inner')"
   ]
  },
  {
   "source": [
    "#Creating predictors\n",
    "\n",
    "#Possible predictor categories (examples)\n",
    "#1. User predictors: How often does a user reorder? \n",
    "#2. Product Predictors: How often is a product reordered?\n",
    "#3. User-Product Predictors: How often does a user buy a specific product?"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This could be made into a simple function call with dictionary arguments or **kwargs\n",
    "total_orders_feature = prior_orders.groupby('user_id').agg(\n",
    "    total_orders = pd.NamedAgg(column='order_number', aggfunc='max')\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_reorder_ratio = prior_orders.groupby('user_id').agg(\n",
    "    reorder_ratio = pd.NamedAgg(column='reordered', aggfunc='mean')\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining the two user features on id 'user_id'\n",
    "user_features = total_orders_feature.merge(user_reorder_ratio, on='user_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product features\n",
    "\n",
    "total_product_purchases = prior_orders.groupby('product_id').agg(\n",
    "    total_product_purchases = pd.NamedAgg(column='order_id', aggfunc='count')\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_reorder_ratio = prior_orders.groupby('product_id').agg(\n",
    "    product_reorder_ratio = pd.NamedAgg(column='reordered', aggfunc='mean')\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the probability is higher than 50%, we might have a better predictor than a coin toss\n",
    "product_reorder_ratio_filtered = product_reorder_ratio.loc[product_reorder_ratio['product_reorder_ratio'] > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join product features\n",
    "product_features = total_product_purchases.merge(product_reorder_ratio_filtered, on='product_id', how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-product predictors\n",
    "total_product_buys = prior_orders.groupby(['user_id', 'product_id']).agg(\n",
    "    total_product_buys = pd.NamedAgg(column='order_id', aggfunc='count')\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to Cart Order as an Ordinal Feature\n",
    "pre_binning_dataframe = prior_orders.copy()\n",
    "\n",
    "pre_binning_dataframe['add_to_cart_sequence'] = pd.cut(pre_binning_dataframe['add_to_cart_order'], bins=[1, 10, 20, float('Inf')], labels=[0, 1, 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_feature_behaviour = total_product_buys.merge(pre_binning_dataframe[['user_id', 'product_id', 'add_to_cart_sequence']].dropna(subset=['add_to_cart_sequence']), on=['user_id', 'product_id'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_user_product = product_feature_behaviour.merge(user_features, on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining features\n",
    "# Using the features_user_product as base since there are both \"product_id\" and \"user_id\" columns\n",
    "features_user_product = features_user_product.merge(product_features, on='product_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    user_id eval_set  order_id\n",
       "10        1    train   1187899\n",
       "25        2    train   1492625\n",
       "38        3     test   2774568\n",
       "44        4     test    329954\n",
       "49        5    train   2196797\n",
       "53        6     test   1528013\n",
       "74        7    train    525192\n",
       "78        8    train    880375\n",
       "82        9    train   1094988\n",
       "88       10    train   1822501"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>eval_set</th>\n      <th>order_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10</th>\n      <td>1</td>\n      <td>train</td>\n      <td>1187899</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>2</td>\n      <td>train</td>\n      <td>1492625</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>3</td>\n      <td>test</td>\n      <td>2774568</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>4</td>\n      <td>test</td>\n      <td>329954</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>5</td>\n      <td>train</td>\n      <td>2196797</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>6</td>\n      <td>test</td>\n      <td>1528013</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>7</td>\n      <td>train</td>\n      <td>525192</td>\n    </tr>\n    <tr>\n      <th>78</th>\n      <td>8</td>\n      <td>train</td>\n      <td>880375</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>9</td>\n      <td>train</td>\n      <td>1094988</td>\n    </tr>\n    <tr>\n      <th>88</th>\n      <td>10</td>\n      <td>train</td>\n      <td>1822501</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "# Setting up the data for modeling\n",
    "# Since the test set was originally used for prediction and test_set_orders are not available, \n",
    "# we will use only the training data later. So, extracting eval_set == \"test\" is not strictly necessary.\n",
    "orders_future = orders[((orders['eval_set']=='train') | (orders['eval_set']=='test'))]\n",
    "orders_future = orders_future[ ['user_id', 'eval_set', 'order_id'] ]\n",
    "orders_future.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep = features_user_product.merge(orders_future, on='user_id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curating training dataframe\n",
    "train_data = data_prep[data_prep['eval_set']=='train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will receive NA values in the reordered column because some user_id/product_id combinations in the training data\n",
    "# might not exist, which means that the user did not reorder a specific product.\n",
    "train_data = train_data.merge(order_products_train[['product_id','order_id', 'reordered']], on=['product_id','order_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We adjust the data accordingly\n",
    "train_data['reordered'] = train_data['reordered'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['total_product_buys', 'total_orders', 'reorder_ratio', 'total_product_purchases', 'product_reorder_ratio', 'add_to_cart_sequence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_clean = train_data[feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   total_product_buys  total_orders  reorder_ratio  total_product_purchases  \\\n",
       "0                  10            10       0.694915                    35791   \n",
       "1                  10            10       0.694915                    35791   \n",
       "2                   1            33       0.502439                    35791   \n",
       "3                   2            11       0.401361                    35791   \n",
       "4                  14            27       0.698225                    35791   \n",
       "5                  14            27       0.698225                    35791   \n",
       "6                  14            27       0.698225                    35791   \n",
       "7                  14            27       0.698225                    35791   \n",
       "8                  14            27       0.698225                    35791   \n",
       "9                  14            27       0.698225                    35791   \n",
       "\n",
       "   product_reorder_ratio add_to_cart_sequence  \n",
       "0                0.77648                    0  \n",
       "1                0.77648                    0  \n",
       "2                0.77648                    0  \n",
       "3                0.77648                    0  \n",
       "4                0.77648                    0  \n",
       "5                0.77648                    0  \n",
       "6                0.77648                    0  \n",
       "7                0.77648                    0  \n",
       "8                0.77648                    0  \n",
       "9                0.77648                    0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>total_product_buys</th>\n      <th>total_orders</th>\n      <th>reorder_ratio</th>\n      <th>total_product_purchases</th>\n      <th>product_reorder_ratio</th>\n      <th>add_to_cart_sequence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10</td>\n      <td>10</td>\n      <td>0.694915</td>\n      <td>35791</td>\n      <td>0.77648</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10</td>\n      <td>10</td>\n      <td>0.694915</td>\n      <td>35791</td>\n      <td>0.77648</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>33</td>\n      <td>0.502439</td>\n      <td>35791</td>\n      <td>0.77648</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>11</td>\n      <td>0.401361</td>\n      <td>35791</td>\n      <td>0.77648</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>14</td>\n      <td>27</td>\n      <td>0.698225</td>\n      <td>35791</td>\n      <td>0.77648</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>14</td>\n      <td>27</td>\n      <td>0.698225</td>\n      <td>35791</td>\n      <td>0.77648</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>14</td>\n      <td>27</td>\n      <td>0.698225</td>\n      <td>35791</td>\n      <td>0.77648</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>14</td>\n      <td>27</td>\n      <td>0.698225</td>\n      <td>35791</td>\n      <td>0.77648</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>14</td>\n      <td>27</td>\n      <td>0.698225</td>\n      <td>35791</td>\n      <td>0.77648</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>14</td>\n      <td>27</td>\n      <td>0.698225</td>\n      <td>35791</td>\n      <td>0.77648</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "train_data_clean.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating test an validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data_clean, train_data['reordered'], train_size=0.8, shuffle=True)\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=HistGradientBoostingClassifier(), n_iter=5,\n",
       "                   n_jobs=8,\n",
       "                   param_distributions={'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f9a06a842b0>,\n",
       "                                        'max_iter': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f9568c0f490>},\n",
       "                   scoring='f1', verbose=10)"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "# Defining the hyperparameter space and fitting a Gradient Booster \n",
    "param_space = {\n",
    "    'learning_rate': stats.uniform(0.01, 0.1),\n",
    "    'max_iter': stats.randint(80, 250),\n",
    "}\n",
    "\n",
    "model = HistGradientBoostingClassifier()\n",
    "search = RandomizedSearchCV(model, param_space, cv=3, n_iter=5, verbose=10, n_jobs=max_cores, scoring='f1')\n",
    "\n",
    "search.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([1616.58908765, 1538.38041409,  792.43772173,  749.81625247,\n",
       "         619.98184665]),\n",
       " 'std_fit_time': array([  2.36199737,   2.78070917, 152.27602075, 129.79063758,\n",
       "          8.3213497 ]),\n",
       " 'mean_score_time': array([219.12606859, 230.78754067, 141.81759938, 152.29845627,\n",
       "        141.27303505]),\n",
       " 'std_score_time': array([ 0.80629427,  1.57525794, 25.01384921, 10.35202759,  5.717522  ]),\n",
       " 'param_learning_rate': masked_array(data=[0.016760583880484174, 0.08840817655222107,\n",
       "                    0.058931133581481505, 0.08197784365231764,\n",
       "                    0.05703840352007857],\n",
       "              mask=[False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_iter': masked_array(data=[183, 241, 80, 199, 162],\n",
       "              mask=[False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'learning_rate': 0.016760583880484174, 'max_iter': 183},\n",
       "  {'learning_rate': 0.08840817655222107, 'max_iter': 241},\n",
       "  {'learning_rate': 0.058931133581481505, 'max_iter': 80},\n",
       "  {'learning_rate': 0.08197784365231764, 'max_iter': 199},\n",
       "  {'learning_rate': 0.05703840352007857, 'max_iter': 162}],\n",
       " 'split0_test_score': array([0.37059055, 0.40236906, 0.39022485, 0.4012926 , 0.39676467]),\n",
       " 'split1_test_score': array([0.37144526, 0.40254602, 0.39101008, 0.3991164 , 0.39714407]),\n",
       " 'split2_test_score': array([0.37122762, 0.40144775, 0.388178  , 0.40038459, 0.39710365]),\n",
       " 'mean_test_score': array([0.37108781, 0.40212095, 0.38980431, 0.40026453, 0.39700413]),\n",
       " 'std_test_score': array([0.00036267, 0.00048147, 0.00119382, 0.00089248, 0.00017012]),\n",
       " 'rank_test_score': array([5, 1, 4, 2, 3], dtype=int32)}"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'learning_rate': 0.08840817655222107, 'max_iter': 241}"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = search.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n         0.0       0.85      0.96      0.90   2989262\n         1.0       0.65      0.29      0.40    729661\n\n    accuracy                           0.83   3718923\n   macro avg       0.75      0.63      0.65   3718923\nweighted avg       0.81      0.83      0.80   3718923\n\n"
     ]
    }
   ],
   "source": [
    "# Output classification report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the classification report, we can deduce that the model is much better at predicting whether a customer does not repurchase a certain product. Precision and recall values for recall are much lower for the positive class, that is for repurchases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}