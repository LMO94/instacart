{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python383jvsc74a57bd0ba7a46ee6710be22c1d8551e12ff7ed3ba252625d60466d682d3a38f8b5abd71",
   "display_name": "Python 3.8.3 64-bit ('py38': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from os import listdir\n",
    "from os import cpu_count\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "from typing import List\n",
    "from toolz.functoolz import pipe\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(data_dir: str) -> List[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    ----------------\n",
    "    data_dir: str\n",
    "      The path where the data is stored\n",
    "\n",
    "    Returns:\n",
    "    ----------------\n",
    "    dataframes_ls: List[pd.DataFrame]\n",
    "      A list of pandas dataframes\n",
    "    \"\"\"\n",
    "    files = [file.split('.')[0] for file in listdir(\"../data\") if file.split('.')[0] != \"\"]\n",
    "\n",
    "    # Creating a string expression to evaluate the data\n",
    "    eval_expr = ', '.join(f'pd.read_csv(\\'../data/{file}.csv\\')' for file in files)\n",
    "\n",
    "    # Evaluating the expression and assigning it, which creates a list of dataframes\n",
    "    dataframes_ls = eval(eval_expr)\n",
    "\n",
    "    return dataframes_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = import_data(\"../data\")\n",
    "files = [file.split('.')[0] for file in listdir(\"../data\")]\n",
    "files_dict = dict(zip(files, range(len(files))))\n",
    "products = dataframes[files_dict['products']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = pq.read_table('./dummy_k13.parquet').to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data_named = pd.merge(cluster_data, products, on='product_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data_named['product_id'] = cluster_data_named['product_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data_by_cluster(data: pd.DataFrame, cluster_num: int):\n",
    "    return data.loc[data['cluster'] == cluster_num, :]"
   ]
  },
  {
   "source": [
    "clusters_separated = [filter_data_by_cluster(cluster_data_named, cluster_num) for cluster_num in range(0, len(cluster_data_named['cluster'].unique()))]"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_lookup = dict(zip(products['product_id'].astype(str).to_list(), products['product_name'].to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('product_lookup.pkl', 'wb') as file:\n",
    "    pickle.dump(product_lookup, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_users_per_cluster = [clusters_separated[i]['user_id'].unique().tolist() for i in range(0, len(clusters_separated))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_purchases_per_user(data: pd.DataFrame, user_id: int):\n",
    "    return data[data['user_id'] == user_id]['product_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_user_purchase_history_in_cluster(cluster_index: int):\n",
    "    return [return_purchases_per_user(clusters_separated[cluster_index], user_id) for user_id in unique_users_per_cluster[cluster_index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchase_history_in_cluster = [generate_user_purchase_history_in_cluster(cluster_index) for cluster_index in range(0, len(clusters_separated))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_item2vec_model(purchases_data):\n",
    "\n",
    "    model = Word2Vec(window = 12, sg = 1, hs = 0, negative = 10, alpha=0.03,min_alpha=0.0007, seed = 28101997, workers=4)\n",
    "\n",
    "    model.build_vocab(purchases_data, progress_per=200)\n",
    "\n",
    "    model.train(purchases_data, total_examples = model.corpus_count, \n",
    "            epochs=10, report_delay=1)\n",
    "\n",
    "    return model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [build_item2vec_model(purchase_history) for purchase_history in purchase_history_in_cluster]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_word_vectors(item_vectors, id: int):\n",
    "    item_vectors.save(f'../item_vectors/item_vectors_cluster_{id}.kv')\n",
    "    return f\"Item vectors for cluster {id} successfully saved.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Item vectors for cluster 0 successfully saved.',\n",
       " 'Item vectors for cluster 1 successfully saved.',\n",
       " 'Item vectors for cluster 2 successfully saved.',\n",
       " 'Item vectors for cluster 3 successfully saved.',\n",
       " 'Item vectors for cluster 4 successfully saved.',\n",
       " 'Item vectors for cluster 5 successfully saved.',\n",
       " 'Item vectors for cluster 6 successfully saved.',\n",
       " 'Item vectors for cluster 7 successfully saved.',\n",
       " 'Item vectors for cluster 8 successfully saved.',\n",
       " 'Item vectors for cluster 9 successfully saved.',\n",
       " 'Item vectors for cluster 10 successfully saved.',\n",
       " 'Item vectors for cluster 11 successfully saved.',\n",
       " 'Item vectors for cluster 12 successfully saved.']"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "[save_word_vectors(models[i], i) for i in range(len(models))]"
   ]
  }
 ]
}